__API предоставляет следующую функциональность:__
1) Обучение ML-моделей с возможностью настройки гиперпараметров.
2) Гиперпараметры для разных моделей могут быть разные.
3) Количество классов моделей доступных для обучения == 2. На данный момент программа позволяет решать задачи регрессии и классификации с помощью моделей Random Forest и SVM.

В базе данных Posgres осуществляется хранение данных о качестве обученных моделей.  
Структура таблицы:  
    - id: инкрементальный id  
    - model_id: id модели  
    - problem: classification или regression  
    - model_name: Random Forest или SVM  
    - h_tune: True или False - нужен ли подбор гиперпараметров  
    - metric: метрика качества. Accuracy для классификации, RMSE для регрессии  
    - metric_value: значение метрики качества  

__Запуск Api, Базу данных и воркеров осуществляется из командной строки с помощью docker-compose:__

1. Используем виртуальное окружение: ``source flask-app/venv/bin/activate``
2. Запускаем ``docker-compose up —build``

__Работа с Api:__

1. Общая информация по моделям:
``r_n = requests.get('http://0.0.0.0:5000/api/ml_models')``
- получить список моделей, доступных для обучения: ``r_n.json()[0]``
- получить список обученных моделей: ``r_n.json()[1]``
- id модели и пути, где они лежат:
``[s['id'] for s in r_n.json()[1]]``
2. Получение предсказаний конкретной модели:
    1) Получить по id модели номер задачи воркера:
    ``r_n = requests.get('http://0.0.0.0:5000/api/ml_models/1')``
    ``t_id = r_n.json().split()[-1]``
    2) По номеру задачи получить предсказания
    ``r_n = requests.get(f'http://0.0.0.0:5000/results/{t_id}')``
    ``prediction = r_n.json()``
3. Обучение новой модели:
 ``data={'problem': 'classification', 'name': 'Random Forest', 'h_tune': False, 'X':X.tolist(), 'y':y.tolist()}``
 ``requests.post('http://0.0.0.0:5000/api/ml_models', json=data)``
 
   Параметры:
   - problem: 'classification', 'regression'
   - name: 'Random Forest', 'SVM'
   - h_tune: нужен ли подбор гиперпараметров (если нужен, выполняется GridSearch по фиксированной сетке)
   - X: список с фичами
   - y: список значений таргета
   
4. Удаление обученной модели:
``requests.delete('http://0.0.0.0:5000/api/ml_models/{id}')``
5. Переобучение модели:
``requests.put('http://0.0.0.0:5000/api/ml_models/4', 
             json={'problem': 'classification', 'name': 'Random Forest', 'h_tune': True})``

__Получить метрики по моделям - работа с Базой данных Posgres:__

1. Положить данные о метриках по модели в БД:
``requests.post('http://0.0.0.0:5000/metrics/2')``
2. Получить метрики по модели из БД
``r_n = requests.get('http://0.0.0.0:5000/metrics/2')``
``r_n.json()``
3. Обновить данные по переобученной модели
``requests.put('http://0.0.0.0:5000/metrics/3')``
4. Удалить данные о метриках модели из БД
``requests.delete('http://0.0.0.0:5000/metrics/3')``

Это релиз. При дальнейших доработках можно учесть:
- обработку ошибок при добавлении неверных типов данных, неподходящих под задачу
- реализовать возможность задания гиперпараметров
- возможность скачивания модели пользователем
- др.

